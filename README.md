# Deep Learning with TensorFlow
This repo contains six Jupyter notebooks, each one an assignment from the Udacity Deep Learning course.
Here's a summary of each notebook.

## 1_notmnist
We train a logistic regression model to classify different alphabet letters printed with various fonts.
Most of the work focuses on understanding the dataset and transforming it into a desirable format for the following assignments.

## 2_fullyconnected
We train a fully connected neural network with one hidden layer using stochastic gradient descent.

## 3_regularization
We study the effects of various normalization schemes, e.g. L2, dropout, max norm, and decaing learning rates. We implement them in a neural network with two fully connected hidden layers.

## 4_convolutions
We introduce convolutions into our neural networks, along with pooling. We develop a neural network with the so-called "Inception module."

## 5_word2vec
We train a neural network on a corpus of English text from Wikipedia articles to develop a vector representation of words using the CBOW model.
We apply t-SNE to this vector embedding to visualize the relation between different words.

## 6_lstm
We train a dynamic sequence-to-sequence RNN with LSTM encoder and decoder cells capable of accepting sequences of variable lengths and returning them in reverse order.
