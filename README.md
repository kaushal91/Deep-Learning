# Deep Learning with TensorFlow
This repo contains six Jupyter notebooks, each one an assignment from the Udacity Deep Learning course.
Here's a summary of each notebook.

## 1_notmnist
We train a logistic regression model to classify different alphabet letters printed with various fonts contained in the NotMNIST dataset.
Most of the work focuses on understanding the dataset and transforming it into a desirable format.

## 2_fullyconnected
We train a fully connected neural network with one hidden layer using stochastic gradient descent on the NotMNIST data.

## 3_regularization
We study the effects of various normalization schemes, e.g. L2, dropout, max norm, and decaing learning rates. We implement them in a neural network with two fully connected hidden layers.

## 4_convolutions
We introduce convolutions into our neural networks, along with pooling. We develop a neural network with the so-called "Inception module."

## 5_word2vec
We develop a vector representation of English words using the CBOW model, and apply t-SNE to this vector embedding to visualize the relation between different words.

## 6_lstm
We train a sequence-to-sequence RNN with LSTM encoder and decoder cells capable of accepting sequences of variable lengths and returning them in reverse order.
